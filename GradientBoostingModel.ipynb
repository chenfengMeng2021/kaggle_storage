{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Pandas requires version '3.0.0' or newer of 'jinja2' (version '2.11.2' currently installed).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-62ae37225fc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pycaret/regression/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pycaret.regression.functional import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0madd_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mautoml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mblend_models\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcheck_drift\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pycaret/regression/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallelBackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_logger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moop\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRegressionExperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDATAFRAME_LIKE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSEQUENCE_LIKE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTARGET_LIKE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_if_global_is_not_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pycaret/regression/oop.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_all_metric_containers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m from pycaret.containers.models.regression import (\n\u001b[1;32m     12\u001b[0m     \u001b[0mALL_ALLOWED_ENGINES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pycaret/containers/metrics/regression.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_container\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_metric\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetricContainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pycaret/containers/base_container.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pycaret/utils/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/style.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_to_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mjinja2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"jinja2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"DataFrame.style requires jinja2.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m from pandas.io.formats.style_render import (\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/compat/_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Pandas requires version '3.0.0' or newer of 'jinja2' (version '2.11.2' currently installed)."
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pycaret.regression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install upgrade pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "prompts_df = pd.read_csv('./prompts_train.csv')\n",
    "summaries_df = pd.read_csv('./summaries_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "merged_df = pd.merge(summaries_df, prompts_df, on='prompt_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate n-gram overlap between two texts\n",
    "def ngram_overlap(text1, text2, n=2):\n",
    "    # Create n-grams for each text\n",
    "    ngrams1 = list(ngrams(text1.split(), n))\n",
    "    ngrams2 = list(ngrams(text2.split(), n))\n",
    "    \n",
    "    # Create counters for n-grams\n",
    "    counter1 = Counter(ngrams1)\n",
    "    counter2 = Counter(ngrams2)\n",
    "    \n",
    "    # Calculate the overlap\n",
    "    common_ngrams = sum((counter1 & counter2).values())\n",
    "    total_ngrams = sum((counter1 | counter2).values())\n",
    "    \n",
    "    return common_ngrams / total_ngrams if total_ngrams > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create features for a given DataFrame\n",
    "def create_features(df):\n",
    "    \n",
    "    # Calculate text length features\n",
    "    df['summary_length'] = df['text'].apply(len)\n",
    "    df['article_length'] = df['prompt_text'].apply(len)\n",
    "    df['length_ratio'] = df['summary_length'] / df['article_length']\n",
    "\n",
    "    # Calculate TF-IDF based cosine similarity between the summary and the article\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['text'].tolist() + df['prompt_text'].tolist())\n",
    "    cosine_similarities = cosine_similarity(tfidf_matrix[:len(df)], tfidf_matrix[len(df):])\n",
    "    df['cosine_similarity'] = cosine_similarities.diagonal()\n",
    "\n",
    "    # Calculate vocabulary richness in the summary\n",
    "    df['vocab_richness'] = df['text'].apply(lambda x: len(set(x.split())) / len(x.split()) if len(x.split()) > 0 else 0)\n",
    "\n",
    "    # Calculate bi-gram and tri-gram overlaps between the summary and the article\n",
    "    df['bigram_overlap'] = df.apply(lambda row: ngram_overlap(row['text'], row['prompt_text'], n=2), axis=1)\n",
    "    df['trigram_overlap'] = df.apply(lambda row: ngram_overlap(row['text'], row['prompt_text'], n=3), axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>summary_length</th>\n",
       "      <th>article_length</th>\n",
       "      <th>length_ratio</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>vocab_richness</th>\n",
       "      <th>bigram_overlap</th>\n",
       "      <th>trigram_overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>346</td>\n",
       "      <td>3566</td>\n",
       "      <td>0.097027</td>\n",
       "      <td>0.182623</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>1225</td>\n",
       "      <td>3566</td>\n",
       "      <td>0.343522</td>\n",
       "      <td>0.405863</td>\n",
       "      <td>0.679803</td>\n",
       "      <td>0.032383</td>\n",
       "      <td>0.005057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0095993991fe</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave only started as an experiment w...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>345</td>\n",
       "      <td>3566</td>\n",
       "      <td>0.096747</td>\n",
       "      <td>0.323222</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.017107</td>\n",
       "      <td>0.007728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00c20c6ddd23</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The experimen was orginally about how even whe...</td>\n",
       "      <td>0.567975</td>\n",
       "      <td>0.969062</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>451</td>\n",
       "      <td>3566</td>\n",
       "      <td>0.126472</td>\n",
       "      <td>0.403937</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.029186</td>\n",
       "      <td>0.012121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00d40ad10dc9</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave developed so quickly due to the...</td>\n",
       "      <td>-0.910596</td>\n",
       "      <td>-0.081769</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>145</td>\n",
       "      <td>3566</td>\n",
       "      <td>0.040662</td>\n",
       "      <td>0.183623</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id                                               text  \\\n",
       "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
       "1  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
       "2  0095993991fe    814d6b  The third wave only started as an experiment w...   \n",
       "3  00c20c6ddd23    814d6b  The experimen was orginally about how even whe...   \n",
       "4  00d40ad10dc9    814d6b  The third wave developed so quickly due to the...   \n",
       "\n",
       "    content   wording                                    prompt_question  \\\n",
       "0  0.205683  0.380538  Summarize how the Third Wave developed over su...   \n",
       "1  3.272894  3.219757  Summarize how the Third Wave developed over su...   \n",
       "2  0.205683  0.380538  Summarize how the Third Wave developed over su...   \n",
       "3  0.567975  0.969062  Summarize how the Third Wave developed over su...   \n",
       "4 -0.910596 -0.081769  Summarize how the Third Wave developed over su...   \n",
       "\n",
       "     prompt_title                                        prompt_text  \\\n",
       "0  The Third Wave  Background \\r\\nThe Third Wave experiment took ...   \n",
       "1  The Third Wave  Background \\r\\nThe Third Wave experiment took ...   \n",
       "2  The Third Wave  Background \\r\\nThe Third Wave experiment took ...   \n",
       "3  The Third Wave  Background \\r\\nThe Third Wave experiment took ...   \n",
       "4  The Third Wave  Background \\r\\nThe Third Wave experiment took ...   \n",
       "\n",
       "   summary_length  article_length  length_ratio  cosine_similarity  \\\n",
       "0             346            3566      0.097027           0.182623   \n",
       "1            1225            3566      0.343522           0.405863   \n",
       "2             345            3566      0.096747           0.323222   \n",
       "3             451            3566      0.126472           0.403937   \n",
       "4             145            3566      0.040662           0.183623   \n",
       "\n",
       "   vocab_richness  bigram_overlap  trigram_overlap  \n",
       "0        0.836066        0.003063         0.000000  \n",
       "1        0.679803        0.032383         0.005057  \n",
       "2        0.833333        0.017107         0.007728  \n",
       "3        0.776316        0.029186         0.012121  \n",
       "4        0.925926        0.006483         0.000000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create features for the test set\n",
    "merged_df = create_features(merged_df)\n",
    "\n",
    "# Show first few rows of the feature-engineered test dataframe\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training set into development and train sets\n",
    "train_df, dev_df = train_test_split(merged_df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "gb_model_content = GradientBoostingRegressor(random_state=42)\n",
    "gb_model_wording = GradientBoostingRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and Target Variables\n",
    "features = ['summary_length', 'article_length', 'length_ratio', 'cosine_similarity', 'vocab_richness', 'bigram_overlap', 'trigram_overlap']\n",
    "target_content = 'content'\n",
    "target_wording = 'wording'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "X_train = train_df[features]\n",
    "y_train_content = train_df[target_content]\n",
    "y_train_wording = train_df[target_wording]\n",
    "\n",
    "X_dev = dev_df[features]\n",
    "y_dev_content = dev_df[target_content]\n",
    "y_dev_wording = dev_df[target_wording]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate a model\n",
    "def train_evaluate(model, X_train, y_train, X_dev, y_dev):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_dev)\n",
    "    rmse = np.sqrt(mean_squared_error(y_dev, y_pred))\n",
    "    return model, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models for 'content' score\n",
    "gb_content, rmse_gb_content = train_evaluate(gb_model_content, X_train, y_train_content, X_dev, y_dev_content)\n",
    "\n",
    "# Train and evaluate models for 'wording' score\n",
    "gb_wording, rmse_gb_wording = train_evaluate(gb_model_wording, X_train, y_train_wording, X_dev, y_dev_wording)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient model RMSE content:0.4344979354904358\n",
      "Gradient model RMSE wording:0.5880323920195103\n",
      "Gradient model MCRMSE:0.511265163754973\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Show the evaluation results\n",
    "print(f\"Gradient model RMSE content:{rmse_gb_content}\\nGradient model RMSE wording:{rmse_gb_wording}\\nGradient model MCRMSE:{(rmse_gb_content + rmse_gb_wording)/2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'ls', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(gb_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized Search Parameters\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GridSearchCV objects for Gradient Boosting\n",
    "gb_grid_search = GridSearchCV(gb_model, param_grid=gb_param_grid, cv=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform Grid Search and return the best model\n",
    "def perform_grid_search(grid_search, X_train, y_train):\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    return best_model, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Fine-tune Model for 'content'\n",
    "best_gb_model_content, best_gb_params_content = perform_grid_search(gb_grid_search, train_df[features], train_df[target_content])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train and Fine-tune Model for 'wording'\n",
    "best_gb_model_wording, best_gb_params_wording = perform_grid_search(gb_grid_search, train_df[features], train_df[target_wording])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting: RMSE Content = 0.43833797730604956, RMSE Wording = 0.5866782896609213, MCRMSE = 0.5125081334834855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Predict 'content' and 'wording' scores on the development set\n",
    "y_pred_gb_content = best_gb_model_content.predict(dev_df[features])\n",
    "\n",
    "y_pred_gb_wording = best_gb_model_wording.predict(dev_df[features])\n",
    "\n",
    "# Calculate RMSE for 'content' and 'wording' for each model\n",
    "rmse_gb_content = calculate_rmse(dev_df[target_content], y_pred_gb_content)\n",
    "\n",
    "rmse_gb_wording = calculate_rmse(dev_df[target_wording], y_pred_gb_wording)\n",
    "\n",
    "# Calculate MCRMSE (Mean Column-wise Root Mean Squared Error)\n",
    "mcrmse_gb = np.mean([rmse_gb_content, rmse_gb_wording])\n",
    "\n",
    "print(f\"Gradient Boosting: RMSE Content = {rmse_gb_content}, RMSE Wording = {rmse_gb_wording}, MCRMSE = {mcrmse_gb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized Search for Random Forest and Gradient Boosting\n",
    "\n",
    "gb_random_search = RandomizedSearchCV(gb_model, param_distributions=gb_param_grid, n_iter=5, cv=3, random_state=42)\n",
    "\n",
    "# Train and Fine-tune Model for 'content'\n",
    "gb_random_search.fit(train_df[features], train_df[target_content])\n",
    "best_gb_model_content = gb_random_search.best_estimator_\n",
    "\n",
    "# Train and Fine-tune Model for 'wording'\n",
    "gb_random_search.fit(train_df[features], train_df[target_wording])\n",
    "best_gb_model_wording = gb_random_search.best_estimator_\n",
    "\n",
    "# You can then evaluate these best models on your development set or make predictions on your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting: RMSE Content = 0.43833797730604956, RMSE Wording = 0.5866782896609213, MCRMSE = 0.5125081334834855\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred_gb_content = best_gb_model_content.predict(dev_df[features])\n",
    "y_pred_gb_wording = best_gb_model_wording.predict(dev_df[features])\n",
    "\n",
    "rmse_gb_content = calculate_rmse(dev_df[target_content], y_pred_gb_content)\n",
    "rmse_gb_wording = calculate_rmse(dev_df[target_wording], y_pred_gb_wording)\n",
    "\n",
    "mcrmse_gb = np.mean([rmse_gb_content, rmse_gb_wording])\n",
    "\n",
    "print(f\"Gradient Boosting: RMSE Content = {rmse_gb_content}, RMSE Wording = {rmse_gb_wording}, MCRMSE = {mcrmse_gb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'ls', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 42, 'subsample': 0.8, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(best_gb_model_content.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'ls', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(gb_model.get_params())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>summary_length</th>\n",
       "      <th>article_length</th>\n",
       "      <th>length_ratio</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>vocab_richness</th>\n",
       "      <th>bigram_overlap</th>\n",
       "      <th>trigram_overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000ffffff</td>\n",
       "      <td>abc123</td>\n",
       "      <td>Example text 1</td>\n",
       "      <td>Summarize...</td>\n",
       "      <td>Example Title 1</td>\n",
       "      <td>Heading\\nText...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.284005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>222222cccccc</td>\n",
       "      <td>abc123</td>\n",
       "      <td>Example text 3</td>\n",
       "      <td>Summarize...</td>\n",
       "      <td>Example Title 1</td>\n",
       "      <td>Heading\\nText...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.284005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111111eeeeee</td>\n",
       "      <td>def789</td>\n",
       "      <td>Example text 2</td>\n",
       "      <td>Summarize...</td>\n",
       "      <td>Example Title 2</td>\n",
       "      <td>Heading\\nText...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.284005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333333dddddd</td>\n",
       "      <td>def789</td>\n",
       "      <td>Example text 4</td>\n",
       "      <td>Summarize...</td>\n",
       "      <td>Example Title 2</td>\n",
       "      <td>Heading\\nText...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.284005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id            text prompt_question     prompt_title  \\\n",
       "0  000000ffffff    abc123  Example text 1    Summarize...  Example Title 1   \n",
       "1  222222cccccc    abc123  Example text 3    Summarize...  Example Title 1   \n",
       "2  111111eeeeee    def789  Example text 2    Summarize...  Example Title 2   \n",
       "3  333333dddddd    def789  Example text 4    Summarize...  Example Title 2   \n",
       "\n",
       "        prompt_text  summary_length  article_length  length_ratio  \\\n",
       "0  Heading\\nText...              14              15      0.933333   \n",
       "1  Heading\\nText...              14              15      0.933333   \n",
       "2  Heading\\nText...              14              15      0.933333   \n",
       "3  Heading\\nText...              14              15      0.933333   \n",
       "\n",
       "   cosine_similarity  vocab_richness  bigram_overlap  trigram_overlap  \n",
       "0           0.284005             1.0             0.0              0.0  \n",
       "1           0.284005             1.0             0.0              0.0  \n",
       "2           0.284005             1.0             0.0              0.0  \n",
       "3           0.284005             1.0             0.0              0.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_test_df = pd.read_csv('prompts_test.csv')\n",
    "summaries_test_df = pd.read_csv('summaries_test.csv')\n",
    "merged_test_df = pd.merge(summaries_test_df, prompts_test_df, on='prompt_id')\n",
    "\n",
    "merged_test_df = create_features(merged_test_df)\n",
    "\n",
    "# Show first few rows of the feature-engineered test dataframe\n",
    "merged_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = merged_test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content prediction: [-0.93703228 -0.93703228 -0.93703228 -0.93703228]\n",
      "Wording prediction: [0.25802261 0.25802261 0.25802261 0.25802261]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Content prediction: {gb_model_content.predict(test_features)}\")\n",
    "print(f\"Wording prediction: {gb_model_wording.predict(test_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
